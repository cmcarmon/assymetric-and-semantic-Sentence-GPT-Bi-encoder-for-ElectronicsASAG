{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e489b1-97cf-4203-a6c8-b4bb9999235b",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfcda755-bb7b-409e-8b1c-1a0195e44270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import sys\n",
    "import gensim.utils as gensimUtils\n",
    "\n",
    "# Get our models - The package will take care of downloading the models automatically\n",
    "# For best performance: Muennighoff/SGPT-5.8B-weightedmean-nli-bitfit\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\")\n",
    "model = AutoModel.from_pretrained(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\")\n",
    "# Deactivate Dropout (There is no dropout in the above models so it makes no difference here but other SGPT models may have dropout)\n",
    "model.eval()\n",
    "\n",
    "# Tokenize input \n",
    "\n",
    "queries = [\n",
    "    \"I'm searching for a planet not too far from Earth.\",\n",
    "]\n",
    "\n",
    "docs = [\n",
    "    \"Neptune is the eighth and farthest-known Solar planet from the Sun. In the Solar System, it is the fourth-largest planet by diameter, the third-most-massive planet, and the densest giant planet. It is 17 times the mass of Earth, slightly more massive than its near-twin Uranus.\",\n",
    "    \"TRAPPIST-1d, also designated as 2MASS J23062928-0502285 d, is a small exoplanet (about 30% the mass of the earth), which orbits on the inner edge of the habitable zone of the ultracool dwarf star TRAPPIST-1 approximately 40 light-years (12.1 parsecs, or nearly 3.7336×1014 km) away from Earth in the constellation of Aquarius.\",\n",
    "    \"A harsh desert world orbiting twin suns in the galaxy’s Outer Rim, Tatooine is a lawless place ruled by Hutt gangsters. Many settlers scratch out a living on moisture farms, while spaceport cities such as Mos Eisley and Mos Espa serve as home base for smugglers, criminals, and other rogues.\",\n",
    "]\n",
    "\n",
    "texts = [\n",
    "    \"deep learning\",\n",
    "    \"artificial intelligence\",\n",
    "    \"deep diving\",\n",
    "    \"artificial snow\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d8988-ea5f-4fba-b1d9-09eade15a820",
   "metadata": {},
   "source": [
    "# Response dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a11b10d7-09ea-44c6-9ba2-422d2464a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\"\"]\n",
    "\n",
    "ET=pd.read_csv('ETresp21question-no-image.csv', encoding='latin1') #get data from student responses set\n",
    "df = pd.DataFrame(ET)    #set ET as dataframe\n",
    "dfIdeal = pd.DataFrame({'Gsentences': ET.GA}) #define ideal answers for tokenization (good answers/Gans).\n",
    "dfIdeal['tokenized_sents'] = dfIdeal.apply(lambda row: nltk.word_tokenize(row['Gsentences']), axis=1)\n",
    "dfStudent = pd.DataFrame({'Ssentences': ET.SA}) #define student answers for tokenization.\n",
    "dfStudent['tokenized_sents'] = dfStudent.apply(lambda row: nltk.word_tokenize(row['Ssentences']), axis=1)\n",
    "dfMQ = pd.DataFrame({'MQsentences': ET.MQ}) #define student answers for tokenization.\n",
    "dfMQ['tokenized_sents'] = dfMQ.apply(lambda row: nltk.word_tokenize(row['MQsentences']), axis=1)\n",
    "GansDict = (dfIdeal['tokenized_sents'].to_dict)  #dictionary for tokenized sents\n",
    "SansDict = (dfStudent['tokenized_sents'].to_dict)\n",
    "MQDict = (dfMQ['tokenized_sents'].to_dict)\n",
    "\n",
    "\n",
    "tokenizedGans = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=1, max_len=14)) for i in ET.GA] #tokenize Gans and Sans for use in w2v, w2vB, and D2V models matching(LSA allows for unkown terms in tokenized strings. these other models do not.)\n",
    "tokenizedSans = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=1, max_len=14)) for i in ET.SA]\n",
    "tokenizedMQ = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=1, max_len=14)) for i in ET.MQ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae4ff5-0d10-4941-be4b-880aa58f0b62",
   "metadata": {},
   "source": [
    "# Inputs from response set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "833c2ba7-40ec-479a-b513-451d305d5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAlist = []\n",
    "for i in ET.GA[0:100]:\n",
    "    GAlist.append(i)\n",
    "    \n",
    "MQlist = []\n",
    "for i in ET.MQ[0:100]:\n",
    "    MQlist.append(i)\n",
    "    \n",
    "SAlist = []\n",
    "for i in ET.SA[0:100]:\n",
    "    SAlist.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e2720-f044-45b7-8947-fd53a8f29c36",
   "metadata": {},
   "source": [
    "# Asymmetric Semantic search Bi-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3a7be61-f6b3-412a-933b-abc855bd5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between \"Rheostat is a resistor which can be adjusted to maintain the flow and when resistance \" and \"  If we increase the...\" is: 0.620\n",
      "Cosine similarity between \"the voltmeter would get a lower reading depending on how high the rheostat resistance is which might raise or lower the amount of A (amps) the circuit gives.\" and \"  If we increase the...\" is: 0.821\n",
      "Cosine similarity between \"The reading would be lower.\" and \"  If we increase the...\" is: 0.510\n"
     ]
    }
   ],
   "source": [
    "SPECB_QUE_BOS = tokenizer.encode(\"[\", add_special_tokens=False)[0]\n",
    "SPECB_QUE_EOS = tokenizer.encode(\"]\", add_special_tokens=False)[0]\n",
    "\n",
    "SPECB_DOC_BOS = tokenizer.encode(\"{\", add_special_tokens=False)[0]\n",
    "SPECB_DOC_EOS = tokenizer.encode(\"}\", add_special_tokens=False)[0]\n",
    "\n",
    "\n",
    "def tokenize_with_specb(texts, is_query):\n",
    "    # Tokenize without padding\n",
    "    batch_tokens = tokenizer(texts, padding=False, truncation=True)   \n",
    "    # Add special brackets & pay attention to them\n",
    "    for seq, att in zip(batch_tokens[\"input_ids\"], batch_tokens[\"attention_mask\"]):\n",
    "        if is_query:\n",
    "            seq.insert(0, SPECB_QUE_BOS)\n",
    "            seq.append(SPECB_QUE_EOS)\n",
    "        else:\n",
    "            seq.insert(0, SPECB_DOC_BOS)\n",
    "            seq.append(SPECB_DOC_EOS)\n",
    "        att.insert(0, 1)\n",
    "        att.append(1)\n",
    "    # Add padding\n",
    "    batch_tokens = tokenizer.pad(batch_tokens, padding=True, return_tensors=\"pt\")\n",
    "    return batch_tokens\n",
    "\n",
    "def get_weightedmean_embedding(batch_tokens, model):\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        # Get hidden state of shape [bs, seq_len, hid_dim]\n",
    "        last_hidden_state = model(**batch_tokens, output_hidden_states=True, return_dict=True).last_hidden_state\n",
    "\n",
    "    # Get weights of shape [bs, seq_len, hid_dim]\n",
    "    weights = (\n",
    "        torch.arange(start=1, end=last_hidden_state.shape[1] + 1)\n",
    "        .unsqueeze(0)\n",
    "        .unsqueeze(-1)\n",
    "        .expand(last_hidden_state.size())\n",
    "        .float().to(last_hidden_state.device)\n",
    "    )\n",
    "\n",
    "    # Get attn mask of shape [bs, seq_len, hid_dim]\n",
    "    input_mask_expanded = (\n",
    "        batch_tokens[\"attention_mask\"]\n",
    "        .unsqueeze(-1)\n",
    "        .expand(last_hidden_state.size())\n",
    "        .float()\n",
    "    )\n",
    "\n",
    "    # Perform weighted mean pooling across seq_len: bs, seq_len, hidden_dim -> bs, hidden_dim\n",
    "    sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded * weights, dim=1)\n",
    "    sum_mask = torch.sum(input_mask_expanded * weights, dim=1)\n",
    "\n",
    "    embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "SAAS_embeddings = get_weightedmean_embedding(tokenize_with_specb(SAlist, is_query=True), model)\n",
    "MQAS_embeddings = get_weightedmean_embedding(tokenize_with_specb(MQlist, is_query=False), model)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
    "cosine_sim_0_1 = 1 - cosine(SAAS_embeddings[0], MQAS_embeddings[0])\n",
    "cosine_sim_0_2 = 1 - cosine(SAAS_embeddings[1], MQAS_embeddings[0])\n",
    "cosine_sim_0_3 = 1 - cosine(SAAS_embeddings[2], MQAS_embeddings[0])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (SAlist[0], MQlist[0][:20] + \"...\", cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (SAlist[1], MQlist[0][:20] + \"...\", cosine_sim_0_2))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (SAlist[2], MQlist[0][:20] + \"...\", cosine_sim_0_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12834499-cfab-4588-b387-aef9d93023c9",
   "metadata": {},
   "source": [
    "# Cosine list for both input response sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e113c31a-a745-42e0-ac42-d90b9cb47a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12736131250858307, 0.1854763627052307, 0.12181951105594635, 0.11131986975669861, 0.17403863370418549, 0.16832676529884338, 0.12686890363693237, 0.16850033402442932, 0.13741858303546906, 0.14134857058525085, 0.12354488670825958, 0.18271340429782867, 0.14072087407112122, 0.13712887465953827, 0.15493068099021912, 0.18470221757888794, 0.14896194636821747, 0.09164448827505112, 0.10320374369621277, 0.1661560982465744, 0.1313747763633728, 0.18755175173282623, 0.1781081259250641, 0.16344980895519257, 0.19030475616455078, 0.19915719330310822, 0.1593693345785141, 0.13995596766471863, 0.20227795839309692, 0.08410131931304932, 0.18821750581264496, 0.14997677505016327, 0.1589668095111847, 0.1438375562429428, 0.14641804993152618, 0.1682250201702118, 0.09792743623256683, 0.14096644520759583, 0.16724646091461182, 0.15622614324092865, 0.08652728796005249, 0.12588538229465485, 0.13371294736862183, 0.15313000977039337, 0.16195830702781677, 0.08967786282300949, 0.18863055109977722, 0.18676070868968964, 0.17596371471881866, 0.21445751190185547, 0.16282494366168976, 0.1864503175020218, 0.14867712557315826, 0.1666310578584671, 0.14497004449367523, 0.1446409523487091, 0.06581587344408035, 0.17991098761558533, 0.2004336565732956, 0.10071545839309692, 0.1763143688440323, 0.15906424820423126, 0.15523108839988708, 0.18070977926254272, 0.04888957738876343, 0.15004530549049377, 0.152867391705513, 0.17960894107818604, 0.05900520086288452, 0.1763530820608139, 0.18878266215324402, 0.16833554208278656, 0.1610771119594574, 0.18275529146194458, 0.22593535482883453, 0.18247929215431213, 0.18424157798290253, 0.1840076744556427, 0.15234345197677612, 0.15759727358818054, 0.19527623057365417, 0.19148387014865875, 0.08651195466518402, 0.18262331187725067, 0.17109116911888123, 0.1664721816778183, 0.1799282282590866, 0.1078060120344162, 0.15766477584838867, 0.22020606696605682, 0.16670092940330505, 0.12150481343269348, 0.18343545496463776, 0.18225517868995667, 0.21405409276485443, 0.18247929215431213, 0.18424157798290253, 0.1840076744556427, 0.15234345197677612, 0.15759727358818054]\n"
     ]
    }
   ],
   "source": [
    "coslist = []\n",
    "i = 0\n",
    "for comp in SAAS_embeddings:\n",
    "    cossim = 1 - cosine(SAAS_embeddings[i], MQAS_embeddings[i])\n",
    "    i += 1\n",
    "    coslist.append(cossim)\n",
    "print(coslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d59ff335-348f-46a3-a2a0-1868a767e878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12736131250858307, 0.1854763627052307, 0.12181951105594635, 0.11131986975669861, 0.17403863370418549, 0.16832676529884338, 0.12686890363693237, 0.16850033402442932, 0.13741858303546906, 0.14134857058525085, 0.12354488670825958, 0.18271340429782867, 0.14072087407112122, 0.13712887465953827, 0.15493068099021912, 0.18470221757888794, 0.14896194636821747, 0.09164448827505112, 0.10320374369621277, 0.1661560982465744, 0.1313747763633728, 0.18755175173282623, 0.1781081259250641, 0.16344980895519257, 0.19030475616455078, 0.19915719330310822, 0.1593693345785141, 0.13995596766471863, 0.20227795839309692, 0.08410131931304932, 0.18821750581264496, 0.14997677505016327, 0.1589668095111847, 0.1438375562429428, 0.14641804993152618, 0.1682250201702118, 0.09792743623256683, 0.14096644520759583, 0.16724646091461182, 0.15622614324092865, 0.08652728796005249, 0.12588538229465485, 0.13371294736862183, 0.15313000977039337, 0.16195830702781677, 0.08967786282300949, 0.18863055109977722, 0.18676070868968964, 0.17596371471881866, 0.21445751190185547, 0.16282494366168976, 0.1864503175020218, 0.14867712557315826, 0.1666310578584671, 0.14497004449367523, 0.1446409523487091, 0.06581587344408035, 0.17991098761558533, 0.2004336565732956, 0.10071545839309692, 0.1763143688440323, 0.15906424820423126, 0.15523108839988708, 0.18070977926254272, 0.04888957738876343, 0.15004530549049377, 0.152867391705513, 0.17960894107818604, 0.05900520086288452, 0.1763530820608139, 0.18878266215324402, 0.16833554208278656, 0.1610771119594574, 0.18275529146194458, 0.22593535482883453, 0.18247929215431213, 0.18424157798290253, 0.1840076744556427, 0.15234345197677612, 0.15759727358818054, 0.19527623057365417, 0.19148387014865875, 0.08651195466518402, 0.18262331187725067, 0.17109116911888123, 0.1664721816778183, 0.1799282282590866, 0.1078060120344162, 0.15766477584838867, 0.22020606696605682, 0.16670092940330505, 0.12150481343269348, 0.18343545496463776, 0.18225517868995667, 0.21405409276485443, 0.18247929215431213, 0.18424157798290253, 0.1840076744556427, 0.15234345197677612, 0.15759727358818054]\n"
     ]
    }
   ],
   "source": [
    "GPTassymBE = []\n",
    "\n",
    "for i in coslist:\n",
    "    GPTassymBE.append(i)\n",
    "print(GPTassymBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9379d008-2c0b-4f18-97dd-2b06a7ecd636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45008512-1e5f-469a-8783-74b559e697b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "949c70e6-aea2-47c1-a1e9-6a35ce005c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e66c30-adda-41c8-aa4b-864e1c37a278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddd809c1-ce8a-484d-8a0f-23f44c18ae4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbae7c-47a5-4f83-9a01-a474329b5df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f27284f6-9514-4c79-9378-f774d52b59d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4380a15-ff33-4b16-97bc-6907b1b9e23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd46d81-8e2b-406b-aaa2-a6cc24ea5674",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5f4b16-5997-4327-80c8-d568f0bbe9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e15a9-c28b-4093-b327-32395fd9f715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25297fff-5a31-4477-aba1-ba9a9502a53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5824c248-b03c-4db0-859e-0fd7e685bd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241cefee-8667-484e-8f08-b8d8a1ef171a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0429ab3-9e9d-42af-ac3e-4a72fc47c983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa138e-dff2-4262-854e-5d0139ff9aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
