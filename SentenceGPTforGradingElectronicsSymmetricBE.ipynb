{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e489b1-97cf-4203-a6c8-b4bb9999235b",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9164a90a-050c-4b55-b65f-836a2c817a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import sys\n",
    "import gensim.utils as gensimUtils\n",
    "\n",
    "# Get our models - The package will take care of downloading the models automatically\n",
    "# For best performance: Muennighoff/SGPT-5.8B-weightedmean-nli-bitfit\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\")\n",
    "model = AutoModel.from_pretrained(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\")\n",
    "# Deactivate Dropout (There is no dropout in the above models so it makes no difference here but other SGPT models may have dropout)\n",
    "model.eval()\n",
    "\n",
    "# Tokenize input \n",
    "\n",
    "queries = [\n",
    "    \"I'm searching for a planet not too far from Earth.\",\n",
    "]\n",
    "\n",
    "docs = [\n",
    "    \"Neptune is the eighth and farthest-known Solar planet from the Sun. In the Solar System, it is the fourth-largest planet by diameter, the third-most-massive planet, and the densest giant planet. It is 17 times the mass of Earth, slightly more massive than its near-twin Uranus.\",\n",
    "    \"TRAPPIST-1d, also designated as 2MASS J23062928-0502285 d, is a small exoplanet (about 30% the mass of the earth), which orbits on the inner edge of the habitable zone of the ultracool dwarf star TRAPPIST-1 approximately 40 light-years (12.1 parsecs, or nearly 3.7336×1014 km) away from Earth in the constellation of Aquarius.\",\n",
    "    \"A harsh desert world orbiting twin suns in the galaxy’s Outer Rim, Tatooine is a lawless place ruled by Hutt gangsters. Many settlers scratch out a living on moisture farms, while spaceport cities such as Mos Eisley and Mos Espa serve as home base for smugglers, criminals, and other rogues.\",\n",
    "]\n",
    "\n",
    "texts = [\n",
    "    \"deep learning\",\n",
    "    \"artificial intelligence\",\n",
    "    \"deep diving\",\n",
    "    \"artificial snow\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e2720-f044-45b7-8947-fd53a8f29c36",
   "metadata": {},
   "source": [
    "# Asymmetric Semantic search Bi-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3a7be61-f6b3-412a-933b-abc855bd5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between \"Rheostat is a resistor which can be adjusted to maintain the flow and when resistance \" and \" It would stay the s...\" is: 0.266\n",
      "Cosine similarity between \"the voltmeter would get a lower reading depending on how high the rheostat resistance is which might raise or lower the amount of A (amps) the circuit gives.\" and \" It would stay the s...\" is: 0.188\n",
      "Cosine similarity between \"The reading would be lower.\" and \" It would stay the s...\" is: 0.321\n"
     ]
    }
   ],
   "source": [
    "SPECB_QUE_BOS = tokenizer.encode(\"[\", add_special_tokens=False)[0]\n",
    "SPECB_QUE_EOS = tokenizer.encode(\"]\", add_special_tokens=False)[0]\n",
    "\n",
    "SPECB_DOC_BOS = tokenizer.encode(\"{\", add_special_tokens=False)[0]\n",
    "SPECB_DOC_EOS = tokenizer.encode(\"}\", add_special_tokens=False)[0]\n",
    "\n",
    "\n",
    "def tokenize_with_specb(texts, is_query):\n",
    "    # Tokenize without padding\n",
    "    batch_tokens = tokenizer(texts, padding=False, truncation=True)   \n",
    "    # Add special brackets & pay attention to them\n",
    "    for seq, att in zip(batch_tokens[\"input_ids\"], batch_tokens[\"attention_mask\"]):\n",
    "        if is_query:\n",
    "            seq.insert(0, SPECB_QUE_BOS)\n",
    "            seq.append(SPECB_QUE_EOS)\n",
    "        else:\n",
    "            seq.insert(0, SPECB_DOC_BOS)\n",
    "            seq.append(SPECB_DOC_EOS)\n",
    "        att.insert(0, 1)\n",
    "        att.append(1)\n",
    "    # Add padding\n",
    "    batch_tokens = tokenizer.pad(batch_tokens, padding=True, return_tensors=\"pt\")\n",
    "    return batch_tokens\n",
    "\n",
    "def get_weightedmean_embedding(batch_tokens, model):\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        # Get hidden state of shape [bs, seq_len, hid_dim]\n",
    "        last_hidden_state = model(**batch_tokens, output_hidden_states=True, return_dict=True).last_hidden_state\n",
    "\n",
    "    # Get weights of shape [bs, seq_len, hid_dim]\n",
    "    weights = (\n",
    "        torch.arange(start=1, end=last_hidden_state.shape[1] + 1)\n",
    "        .unsqueeze(0)\n",
    "        .unsqueeze(-1)\n",
    "        .expand(last_hidden_state.size())\n",
    "        .float().to(last_hidden_state.device)\n",
    "    )\n",
    "\n",
    "    # Get attn mask of shape [bs, seq_len, hid_dim]\n",
    "    input_mask_expanded = (\n",
    "        batch_tokens[\"attention_mask\"]\n",
    "        .unsqueeze(-1)\n",
    "        .expand(last_hidden_state.size())\n",
    "        .float()\n",
    "    )\n",
    "\n",
    "    # Perform weighted mean pooling across seq_len: bs, seq_len, hidden_dim -> bs, hidden_dim\n",
    "    sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded * weights, dim=1)\n",
    "    sum_mask = torch.sum(input_mask_expanded * weights, dim=1)\n",
    "\n",
    "    embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "SAAS_embeddings = get_weightedmean_embedding(tokenize_with_specb(SAlist, is_query=True), model)\n",
    "GAAS_embeddings = get_weightedmean_embedding(tokenize_with_specb(GAlist, is_query=False), model)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
    "cosine_sim_0_1 = 1 - cosine(SAAS_embeddings[0], GAAS_embeddings[0])\n",
    "cosine_sim_0_2 = 1 - cosine(SAAS_embeddings[1], GAAS_embeddings[0])\n",
    "cosine_sim_0_3 = 1 - cosine(SAAS_embeddings[2], GAAS_embeddings[0])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (SAlist[0], GAlist[0][:20] + \"...\", cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (SAlist[1], GAlist[0][:20] + \"...\", cosine_sim_0_2))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (SAlist[2], GAlist[0][:20] + \"...\", cosine_sim_0_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d3e3b-44d0-43d7-bf69-81e05f7906cf",
   "metadata": {},
   "source": [
    "#  response dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d59ff335-348f-46a3-a2a0-1868a767e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\"\"]\n",
    "\n",
    "ET=pd.read_csv('ETrespclean3.csv', encoding='latin1') #get data from student responses set\n",
    "df = pd.DataFrame(ET)    #set ET as dataframe\n",
    "dfIdeal = pd.DataFrame({'Gsentences': ET.GA}) #define ideal answers for tokenization (good answers/Gans).\n",
    "dfIdeal['tokenized_sents'] = dfIdeal.apply(lambda row: nltk.word_tokenize(row['Gsentences']), axis=1)\n",
    "dfStudent = pd.DataFrame({'Ssentences': ET.SA}) #define student answers for tokenization.\n",
    "dfStudent['tokenized_sents'] = dfStudent.apply(lambda row: nltk.word_tokenize(row['Ssentences']), axis=1)\n",
    "Gans = dfIdeal['tokenized_sents'] ##renaming the 2 tokenized sent sets for ease.\n",
    "Sans = dfStudent['tokenized_sents']\n",
    "GansDict = (dfIdeal['tokenized_sents'].to_dict)  #dictionary for tokenized sents\n",
    "SansDict = (dfStudent['tokenized_sents'].to_dict)\n",
    "\n",
    "\n",
    "tokenizedGans = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=1, max_len=14)) for i in ET.GA] #tokenize Gans and Sans for use in w2v, w2vB, and D2V models matching(LSA allows for unkown terms in tokenized strings. these other models do not.)\n",
    "tokenizedSans = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=1, max_len=14)) for i in ET.SA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9379d008-2c0b-4f18-97dd-2b06a7ecd636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949c70e6-aea2-47c1-a1e9-6a35ce005c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAlist = []\n",
    "for i in ET.GA[0:100]:\n",
    "    GAlist.append(i)\n",
    "    \n",
    "SAlist = []\n",
    "for i in ET.SA[0:100]:\n",
    "    SAlist.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45008512-1e5f-469a-8783-74b559e697b2",
   "metadata": {},
   "source": [
    "# sentence embeddings, attention masks, weighting and mean pooling for ideal answers (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e66c30-adda-41c8-aa4b-864e1c37a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokensGA = tokenizer(GAlist, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get the embeddings\n",
    "with torch.no_grad():\n",
    "    # Get hidden state of shape [bs, seq_len, hid_dim]\n",
    "    last_hidden_stateGA = model(**batch_tokensGA, output_hidden_states=True, return_dict=True).last_hidden_state\n",
    "\n",
    "# Get weights of shape [bs, seq_len, hid_dim]\n",
    "weightsGA = (\n",
    "    torch.arange(start=1, end=last_hidden_stateGA.shape[1] + 1)\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(-1)\n",
    "    .expand(last_hidden_stateGA.size())\n",
    "    .float().to(last_hidden_stateGA.device)\n",
    ")\n",
    "\n",
    "# Get attn mask of shape [bs, seq_len, hid_dim]\n",
    "input_mask_expandedGA = (\n",
    "    batch_tokensGA[\"attention_mask\"]\n",
    "    .unsqueeze(-1)\n",
    "    .expand(last_hidden_stateGA.size())\n",
    "    .float()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd809c1-ce8a-484d-8a0f-23f44c18ae4e",
   "metadata": {},
   "source": [
    "# encodings for ideal responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fbae7c-47a5-4f83-9a01-a474329b5df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5642,  1.0927, -0.2866,  ..., -0.1318,  1.1017,  1.3367],\n",
      "        [ 0.5642,  1.0927, -0.2866,  ..., -0.1318,  1.1017,  1.3367],\n",
      "        [ 0.5642,  1.0927, -0.2866,  ..., -0.1318,  1.1017,  1.3367],\n",
      "        ...,\n",
      "        [-0.7614, -0.5094,  0.6846,  ...,  1.2404, -0.1497, -1.2174],\n",
      "        [-0.7614, -0.5094,  0.6846,  ...,  1.2404, -0.1497, -1.2174],\n",
      "        [-0.7614, -0.5094,  0.6846,  ...,  1.2404, -0.1497, -1.2174]])\n"
     ]
    }
   ],
   "source": [
    "# Perform weighted mean pooling across seq_len: bs, seq_len, hidden_dim -> bs, hidden_dim\n",
    "sum_embeddingsGA2 = torch.sum(last_hidden_stateGA * input_mask_expandedGA * weightsGA, dim=1)\n",
    "sum_maskGA = torch.sum(input_mask_expandedGA * weightsGA, dim=1)\n",
    "\n",
    "embeddingsGA = sum_embeddingsGA2 / sum_maskGA\n",
    "print(embeddingsGA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27284f6-9514-4c79-9378-f774d52b59d4",
   "metadata": {},
   "source": [
    "# sentence embeddings, attention masks, weighting and mean pooling for user responses (SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4380a15-ff33-4b16-97bc-6907b1b9e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokensSA = tokenizer(SAlist, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get the embeddings\n",
    "with torch.no_grad():\n",
    "    # Get hidden state of shape [bs, seq_len, hid_dim]\n",
    "    last_hidden_stateSA = model(**batch_tokensSA, output_hidden_states=True, return_dict=True).last_hidden_state\n",
    "\n",
    "# Get weights of shape [bs, seq_len, hid_dim]\n",
    "weightsSA = (\n",
    "    torch.arange(start=1, end=last_hidden_stateSA.shape[1] + 1)\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(-1)\n",
    "    .expand(last_hidden_stateSA.size())\n",
    "    .float().to(last_hidden_stateSA.device)\n",
    ")\n",
    "\n",
    "# Get attn mask of shape [bs, seq_len, hid_dim]\n",
    "input_mask_expandedSA = (\n",
    "    batch_tokensSA[\"attention_mask\"]\n",
    "    .unsqueeze(-1)\n",
    "    .expand(last_hidden_stateSA.size())\n",
    "    .float()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd46d81-8e2b-406b-aaa2-a6cc24ea5674",
   "metadata": {},
   "source": [
    "# encodings for user responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5f4b16-5997-4327-80c8-d568f0bbe9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform weighted mean pooling across seq_len: bs, seq_len, hidden_dim -> bs, hidden_dim\n",
    "sum_embeddingsSA2 = torch.sum(last_hidden_stateSA * input_mask_expandedSA * weightsSA, dim=1)\n",
    "sum_maskSA = torch.sum(input_mask_expandedSA * weightsSA, dim=1)\n",
    "\n",
    "embeddingsSA = sum_embeddingsSA2 / sum_maskSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5e15a9-c28b-4093-b327-32395fd9f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between \"%s\" and \"%s\" is: %.3f 0.2322816550731659\n",
      "Cosine similarity between \"%s\" and \"%s\" is: %.3f 0.1253511607646942\n",
      "Cosine similarity between \"%s\" and \"%s\" is: %.3f 0.26908594369888306\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarities\n",
    "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
    "cosine_sim_0_1 = 1 - cosine(embeddingsSA[0], embeddingsGA[0])\n",
    "cosine_sim_0_2 = 1 - cosine(embeddingsSA[1], embeddingsGA[1])\n",
    "cosine_sim_0_3 = 1 - cosine(embeddingsSA[2], embeddingsGA[2])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\", (cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\", (cosine_sim_0_2))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" ,(cosine_sim_0_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25297fff-5a31-4477-aba1-ba9a9502a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coslist = []\n",
    "i = 0\n",
    "for i in embeddingsSA:\n",
    "    cossim = 1 - cosine(embeddingsSA[0], embeddingsGA[0])\n",
    "    i += 1\n",
    "    coslist.append(cossim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5824c248-b03c-4db0-859e-0fd7e685bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(embeddingsGA, embeddingsSA): \n",
    "      \n",
    "    merged_list = [(embeddingsGA[i], embeddingsSA[i]) for i in range(0, len(embeddingsGA))] \n",
    "    return merged_list \n",
    "\n",
    "embeddingstuple = merge(embeddingsGA, embeddingsSA)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "Combothresh = []\n",
    "for value in embeddingstuple:\n",
    "    if value[0] or value[1] == 1:\n",
    "        Combothresh.append(1)\n",
    "    else:\n",
    "        Combothresh.append(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "241cefee-8667-484e-8f08-b8d8a1ef171a",
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AttributeError'>",
     "evalue": "'torch.dtype' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:/Users/colin/AppData/Local/Temp/xpython_62988/4228197665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddingstuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddingstuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\colinmobile\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcosine\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;31m#   or 'reflective correlation'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# clamp the result to 0-2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\colinmobile\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[1;34m(u, v, w, centered)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mumu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvmu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m     \u001b[0muv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m     \u001b[0muu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[0mvv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\colinmobile\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mscl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\colinmobile\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "print(1 - cosine(embeddingstuple[0], embeddingstuple[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0429ab3-9e9d-42af-ac3e-4a72fc47c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2322816550731659, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304, 0.18029339611530304]\n"
     ]
    }
   ],
   "source": [
    "print(coslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa138e-dff2-4262-854e-5d0139ff9aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
